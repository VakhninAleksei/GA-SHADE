{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b06e272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "import math\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def index_of_agreement (s, o):\n",
    "    s,o = filter_nan(s,o)\n",
    "    ia = 1 -(np.sum((o-s)**2))/(np.sum((np.abs(s-np.mean(o))+np.abs(o-np.mean(o)))**2))\n",
    "    return ia\n",
    "def filter_nan(s,o):\n",
    "\n",
    "    s = np.array(s.copy())\n",
    "    o = np.array(o.copy())\n",
    "    data = np.array([s.flatten(),o.flatten()])\n",
    "    data = np.transpose(data)\n",
    "    data = data[~np.isnan(data).any(1)]\n",
    "    s = data[:,0]\n",
    "    o = data[:,1]\n",
    "    return s, o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e83c3a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"final_dataset.csv\", index_col=0)\n",
    "data.index = pd.to_datetime(data.index)\n",
    "\n",
    "FEATURES = ['Power', 'Temp','T_lag_1', 'T_lag_2', 'T_lag_3', 'E_lag_1', 'E_lag_2', 'E_lag_3','t_cos','t_sin', 'd_cos', 'd_sin', 'w_cos',  'w_sin', 'm_cos', 'm_sin' ]\n",
    "\n",
    "data_test_1 = data[(data['month'] == 3) | (data['month'] == 4) | (data['month'] == 5)]\n",
    "data_train_1 = data[(data['month'] != 3) & (data['month'] != 4) & (data['month'] != 5)]\n",
    "data_test_1 = data_test_1[FEATURES]\n",
    "data_train_1 = data_train_1[FEATURES]\n",
    "\n",
    "data_test_2 = data[(data['month'] == 6) | (data['month'] == 7) | (data['month'] == 8)]\n",
    "data_train_2 = data[(data['month'] != 6) & (data['month'] != 7) & (data['month'] != 8)]   \n",
    "data_test_2 = data_test_2[FEATURES]\n",
    "data_train_2 = data_train_2[FEATURES]\n",
    "\n",
    "data_test_3 = data[(data['month'] == 9) | (data['month'] == 10) | (data['month'] == 11)]\n",
    "data_train_3 = data[(data['month'] != 9) & (data['month'] != 10) & (data['month'] != 11)]  \n",
    "data_test_3 = data_test_3[FEATURES]\n",
    "data_train_3 = data_train_3[FEATURES]\n",
    "\n",
    "data_test_4 = data[(data['month'] == 12) | (data['month'] == 1) | (data['month'] == 2)]\n",
    "data_train_4 = data[(data['month'] != 12) & (data['month'] != 1) & (data['month'] != 2)]\n",
    "data_test_4 = data_test_4[FEATURES]\n",
    "data_train_4 = data_train_4[FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79efdccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_criterions (params,n1,n2):\n",
    "\n",
    "    features = ['Temp','T_lag_1', 'T_lag_2', 'T_lag_3', 'E_lag_1', 'E_lag_2', 'E_lag_3','t_cos','t_sin', 'd_cos', 'd_sin', 'w_cos',  'w_sin', 'm_cos', 'm_sin']\n",
    "    target = ['Power']\n",
    "    feature_variables = params[n1:]\n",
    "    new_features = []\n",
    "    number_of_ones = 0\n",
    "    \n",
    "    for i in range(0, len(feature_variables)):\n",
    "        if (feature_variables[i] == 1):\n",
    "            new_features += [features[i]]\n",
    "    \n",
    "    epochs_ = int(params[0])\n",
    "    layers_ = int(params[1])\n",
    "    neurons_ = int(params[2])\n",
    "    batch_size_ = int(params[3])\n",
    "    learning_rate_ = float(params[4])\n",
    "    \n",
    "    \n",
    "    global_train_MAE = 0.0\n",
    "    global_val_MAE = 0.0\n",
    "    global_test_MAE = 0.0\n",
    "    \n",
    "    global_train_MSE = 0.0\n",
    "    global_val_MSE = 0.0\n",
    "    global_test_MSE = 0.0\n",
    "    \n",
    "    global_train_IA = 0.0\n",
    "    global_val_IA = 0.0\n",
    "    global_test_IA = 0.0\n",
    "    \n",
    "    global_train_R2 = 0.0\n",
    "    global_val_R2 = 0.0\n",
    "    global_test_R2 = 0.0  \n",
    "    \n",
    "    for part in [1,2,3,4]:\n",
    "        data = pd.read_csv('final_dataset.csv', sep = ',', low_memory=False,index_col=0)\n",
    "        if (part == 1):\n",
    "            data_test = data[(data['month'] == 3) | (data['month'] == 4) | (data['month'] == 5)]\n",
    "            data_train = data[(data['month'] != 3) & (data['month'] != 4) & (data['month'] != 5)]\n",
    "\n",
    "        if (part == 2):\n",
    "            data_test = data[(data['month'] == 6) | (data['month'] == 7) | (data['month'] == 8)]\n",
    "            data_train = data[(data['month'] != 6) & (data['month'] != 7) & (data['month'] != 8)]   \n",
    "\n",
    "        if (part == 3):\n",
    "            data_test = data[(data['month'] == 9) | (data['month'] == 10) | (data['month'] == 11)]\n",
    "            data_train = data[(data['month'] != 9) & (data['month'] != 10) & (data['month'] != 11)]  \n",
    "\n",
    "        if (part == 4):\n",
    "            data_test = data[(data['month'] == 12) | (data['month'] == 1) | (data['month'] == 2)]\n",
    "            data_train = data[(data['month'] != 12) & (data['month'] != 1) & (data['month'] != 2)]        \n",
    "\n",
    "        X_train = data_train[new_features]\n",
    "        Y_train = data_train[target]\n",
    "                                                                              \n",
    "        X_test = data_test[new_features]\n",
    "        Y_test = data_test[target]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        scaler.fit(X_train)\n",
    "\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        k=5\n",
    "        X = X_train.copy()\n",
    "        y = np.array(Y_train).flatten().copy()\n",
    "        kf = KFold(n_splits=k, random_state=None, shuffle=False)\n",
    "        kf.get_n_splits(X)\n",
    "\n",
    "        validation_MAE = 0.0\n",
    "        validation_MSE = 0.0\n",
    "        validation_R2 = 0.0\n",
    "        validation_IA = 0.0\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "\n",
    "            x_train, x_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            hidden_layer_sizes = []\n",
    "            for i in range(0,layers_):\n",
    "                hidden_layer_sizes.append(neurons_)\n",
    "            hidden_layer_sizes = tuple(hidden_layer_sizes)\n",
    "            mlp_regressor = MLPRegressor(hidden_layer_sizes=hidden_layer_sizes, max_iter=epochs_, solver='adam',\n",
    "                                     batch_size=batch_size_,\n",
    "                                     learning_rate_init=learning_rate_,learning_rate='constant')\n",
    "            mlp_regressor.fit(x_train, y_train)\n",
    "            y_pred = mlp_regressor.predict(x_test)\n",
    "            \n",
    "            validation_MAE+=mean_absolute_error(y_test, y_pred)\n",
    "            validation_MSE+=mean_squared_error(y_test, y_pred, squared=False)\n",
    "            validation_R2+=r2_score(y_test, y_pred)\n",
    "            validation_IA+=index_of_agreement(y_test, y_pred)\n",
    "\n",
    "        global_val_MAE += validation_MAE/k\n",
    "        global_val_MSE += validation_MSE/k\n",
    "        global_val_R2 += validation_R2/k\n",
    "        global_val_IA += validation_IA/k\n",
    "\n",
    "        hidden_layer_sizes = []\n",
    "        for i in range(0,layers_):\n",
    "            hidden_layer_sizes.append(neurons_)\n",
    "        hidden_layer_sizes = tuple(hidden_layer_sizes)\n",
    "\n",
    "        mlp_regressor = MLPRegressor(hidden_layer_sizes=hidden_layer_sizes, max_iter=epochs_, solver='adam',\n",
    "                                     batch_size=batch_size_,\n",
    "                                     learning_rate_init=learning_rate_,learning_rate='constant')\n",
    "        mlp_regressor.fit(X_train, Y_train)\n",
    "        Y_pred = mlp_regressor.predict(X_train)\n",
    "            \n",
    "        \n",
    "        global_train_MAE += mean_absolute_error(Y_train, Y_pred)\n",
    "        global_train_MSE += mean_squared_error(Y_train, Y_pred)\n",
    "        global_train_R2 += r2_score(Y_train, Y_pred)\n",
    "        global_train_IA += index_of_agreement(Y_train, Y_pred)\n",
    "\n",
    "        Y_pred = mlp_regressor.predict(X_test)\n",
    "        \n",
    "        global_test_MAE+= mean_absolute_error(Y_test, Y_pred)\n",
    "        global_test_MSE+= mean_squared_error(Y_test, Y_pred)\n",
    "        global_test_R2+=r2_score(Y_test, Y_pred)\n",
    "        global_test_IA+=index_of_agreement(Y_test, Y_pred)\n",
    "        \n",
    "   \n",
    "    global_train_MAE = global_train_MAE/4\n",
    "    global_val_MAE = global_val_MAE/4\n",
    "    global_test_MAE = global_test_MAE/4\n",
    "        \n",
    "    \n",
    "    global_train_MSE = global_train_MSE/4\n",
    "    global_val_MSE = global_val_MSE/4\n",
    "    global_test_MSE = global_test_MSE/4\n",
    "    \n",
    "    global_train_R2 = global_train_R2/4\n",
    "    global_val_R2 = global_val_R2/4\n",
    "    global_test_R2 = global_test_R2/4\n",
    "    \n",
    "    global_train_IA = global_train_IA/4\n",
    "    global_val_IA = global_val_IA/4\n",
    "    global_test_IA = global_test_IA/4\n",
    "\n",
    "    return global_train_MAE, global_val_MAE, global_test_MAE,global_train_MSE, global_val_MSE, global_test_MSE, global_train_R2, global_val_R2, global_test_R2, global_train_IA, global_val_IA, global_test_IA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5153d7ca-5acb-49b5-98a6-9aa0d0158e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function(data_test_1,data_train_1, data_test_2,data_train_2,data_test_3,data_train_3,data_test_4,data_train_4, x, variable_type, n1, n2, goal_number_of_features):\n",
    "   \n",
    "    FEATURES = ['Temp','T_lag_1', 'T_lag_2', 'T_lag_3', 'E_lag_1', 'E_lag_2', 'E_lag_3','t_cos','t_sin', 'd_cos', 'd_sin', 'w_cos',  'w_sin', 'm_cos', 'm_sin']\n",
    "    TARGET = ['Power']\n",
    "    \n",
    "    params = x.copy()\n",
    "    feature_variables = params[n1:]\n",
    "    new_features = []\n",
    "    number_of_ones = 0\n",
    "    \n",
    "    for i in range(0, len(feature_variables)):\n",
    "        if (feature_variables[i] == 1):\n",
    "            new_features += [FEATURES[i]]\n",
    "            number_of_ones = number_of_ones +1\n",
    "    for i in range(0, n1):\n",
    "        \n",
    "        if (variable_type[i] == 'int'):\n",
    "            params[i] = int(params[i])\n",
    "   \n",
    "    epochs_ = int(params[0])\n",
    "    layers_ = int(params[1])\n",
    "    neurons_ = int(params[2])\n",
    "    batch_size_ = int(params[3])\n",
    "    learning_rate_ = float(params[4])\n",
    "    \n",
    "    global_val_MAE = 0.0\n",
    "      \n",
    "    \n",
    "    for part in [1,2,3,4]:\n",
    "        if (part == 1):\n",
    "            data_test = data_test_1         \n",
    "            data_train = data_train_1\n",
    "\n",
    "        if (part == 2):\n",
    "            data_test = data_test_2\n",
    "            data_train = data_train_2\n",
    "\n",
    "        if (part == 3):\n",
    "            data_test = data_test_3\n",
    "            data_train = data_train_3\n",
    "\n",
    "        if (part == 4):\n",
    "            data_test = data_test_4\n",
    "            data_train = data_train_4\n",
    "\n",
    "        target = ['Power']\n",
    "        \n",
    "        X_train = data_train[new_features]\n",
    "        Y_train = data_train[target]\n",
    "        \n",
    "        X_test = data_test[new_features]\n",
    "        Y_test = data_test[target]\n",
    "\n",
    "        # Create a scaler object\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        # Fit the scaler on the train data\n",
    "        scaler.fit(X_train)\n",
    "\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        k=5\n",
    "        X = X_train\n",
    "        y = np.array(Y_train).flatten()\n",
    "        kf = KFold(n_splits=k, random_state=None, shuffle=False)\n",
    "        kf.get_n_splits(X)\n",
    "\n",
    "        validation_MAE_in_part = 0.0\n",
    "\n",
    "        \n",
    "        for train_index, test_index in kf.split(X):\n",
    "\n",
    "            x_train, x_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            hidden_layer_sizes = []\n",
    "            for i in range(0,layers_):\n",
    "                hidden_layer_sizes.append(neurons_)\n",
    "            hidden_layer_sizes = tuple(hidden_layer_sizes)\n",
    "\n",
    "            mlp_regressor = MLPRegressor(hidden_layer_sizes=hidden_layer_sizes, max_iter=epochs_, solver='adam',\n",
    "                                     batch_size=batch_size_,\n",
    "                                     learning_rate_init=learning_rate_,learning_rate='constant')\n",
    "            \n",
    "            mlp_regressor.fit(x_train, y_train)\n",
    "            y_pred = mlp_regressor.predict(x_test)\n",
    "\n",
    "            score = mean_absolute_error(y_test, y_pred)\n",
    "            \n",
    "            validation_MAE_in_part += score\n",
    "\n",
    "        \n",
    "        global_val_MAE += validation_MAE_in_part/k\n",
    "    \n",
    "    global_val_MAE =global_val_MAE/4\n",
    "    \n",
    "    penalty = abs(goal_number_of_features -number_of_ones ) +1 ##\n",
    "\n",
    "    return global_val_MAE*penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08800041-292f-4e1b-bfe3-4f9d745d1f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_population(population, pop_size, N, a, b, variable_type):\n",
    "    for i in range(0, pop_size):\n",
    "        for j in range (0, N):\n",
    "            if (variable_type[j] == 'real'):\n",
    "                population[i][j] = random.random()*(b[j]-a[j])+a[j]\n",
    "            if (variable_type[j] == 'int'):\n",
    "                population[i][j] = int(random.random()*(b[j]-a[j])+a[j])\n",
    "            if (variable_type[j] == 'bool'):\n",
    "                if (random.random()>0.5):\n",
    "                    population[i][j] = 1\n",
    "                else:\n",
    "                    population[i][j] = 0\n",
    "\n",
    "def generate_indices(pop_size, A, p, i):\n",
    "    r1=int(random.random()*pop_size)\n",
    "    r2=int(random.random()*(pop_size+A))\n",
    "    max_best_number = int(p[i]*pop_size)\n",
    "    bests_fitness = np.argsort(fitness)[:max_best_number]\n",
    "    pbest = np.random.choice(bests_fitness)\n",
    "    while (r1 == r2 or i == r1 or i == r2 ):\n",
    "        r1=int(random.random()*pop_size)\n",
    "        r2=int(random.random()*(pop_size+A))\n",
    "\n",
    "    return r1, r2, pbest\n",
    "\n",
    "def borders (v, population, N, a, b, variable_type):\n",
    "    for i in range(0, pop_size):\n",
    "        for j in range (0, N):\n",
    "            if (variable_type[j] == 'real'):\n",
    "                if (v[i][j] > b[j]):\n",
    "                    v[i][j] = (b[j]+population[i][j])/2\n",
    "                if (v[i][j] < a[j]):\n",
    "                    v[i][j] = (a[j]+population[i][j])/2\n",
    "            if (variable_type[j] == 'int'):\n",
    "                if (v[i][j] > b[j]):\n",
    "                    v[i][j] = int((b[j]+population[i][j])/2)\n",
    "                if (v[i][j] < a[j]):\n",
    "                    v[i][j] = int((a[j]+population[i][j])/2)\n",
    "def isNaN(num):\n",
    "    return num != num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d5d4cb-e41f-41db-ba9c-70105d8f1ff2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "n1 = 5\n",
    "n2 = 15\n",
    "N = n1 + n2\n",
    "pop_size = 50\n",
    "\n",
    "for goal_number_of_features in [1,2,3,5,7,10,15]:\n",
    "    RUNS = 15\n",
    "    columns = ['epochs', \"layers\", \"neurons\",\"batch_size\",\"learning_rate\", 'Temp','T_lag_1', 'T_lag_2', 'T_lag_3', 'E_lag_1', 'E_lag_2', 'E_lag_3','t_cos','t_sin', 'd_cos', 'd_sin', 'w_cos',  'w_sin', 'm_cos', 'm_sin',\n",
    "            'MAE_train', 'MSE_train', 'IA_train', 'R2_train',\n",
    "            'MAE_val',   'MSE_val',   'IA_val',   'R2_val',\n",
    "            'MAE_test',  'MSE_test',  'IA_test',  'R2_test'\n",
    "              ]\n",
    "    df_stats = pd.DataFrame(columns = columns, index = range(RUNS))\n",
    "    df_fitness = pd.DataFrame(columns = columns, index = range(RUNS))\n",
    "    variable_type =  ['int','int','int','int','real',\n",
    "                      'bool','bool','bool','bool','bool',\n",
    "                      'bool','bool','bool','bool','bool',\n",
    "                      'bool','bool','bool','bool','bool']\n",
    "\n",
    "    a = [1, 2, 5,  1,  0.0001]\n",
    "    b = [200,5, 50, 1024, 1.0]\n",
    "\n",
    "    archive_size = pop_size\n",
    "    H = 10\n",
    "\n",
    "    best_in_RUN = []\n",
    "    fitness_stat = pd.DataFrame()\n",
    "    solution_stat = []\n",
    "\n",
    "    while (RUNS>0):\n",
    "\n",
    "        global_best = 1e300\n",
    "        population = np.empty((pop_size,N))\n",
    "        v = np.empty((pop_size,N))\n",
    "        archive = np.empty((archive_size,N))\n",
    "        fitness = np.empty(pop_size)\n",
    "        fitness_new = np.empty(pop_size)\n",
    "        F_history = np.empty(H)\n",
    "        CR_history = np.empty(H)\n",
    "        S_CR = []\n",
    "        S_F = []\n",
    "        w = []\n",
    "        r = np.empty(pop_size)\n",
    "        CR = np.empty(pop_size)\n",
    "        F = np.empty(pop_size)\n",
    "        p = np.empty(pop_size)\n",
    "        FEV = 2000\n",
    "        kratnost = FEV/100\n",
    "        tracking_fitness = []\n",
    "        tracking_solution = []\n",
    "        init_population(population, pop_size, N, a, b, variable_type)\n",
    "\n",
    "        for i in range (0, pop_size):\n",
    "\n",
    "            x = population[i][:]\n",
    "            solution = x.copy()\n",
    "            sol = solution.copy()\n",
    "            fit = fitness_function(data_test_1,data_train_1, data_test_2,data_train_2,data_test_3,data_train_3,data_test_4,data_train_4,solution, variable_type ,n1, n2, goal_number_of_features)\n",
    "            fitness[i] = fit\n",
    "            fitness_new[i] = fitness[i]\n",
    "            FEV =FEV - 1\n",
    "\n",
    "            if (fitness[i]<global_best):\n",
    "                global_best = fitness[i]\n",
    "                best_solution = solution.copy()\n",
    "\n",
    "            if (FEV % kratnost == 0):\n",
    "                tracking_fitness.append(global_best)\n",
    "                tracking_solution = (best_solution)\n",
    "\n",
    "        F_history[:] = 0.5\n",
    "        CR_history[:] = 0.5\n",
    "        A = 0\n",
    "        k=0\n",
    "        pmin = 5.0/pop_size\n",
    "\n",
    "        while (FEV>0):\n",
    "            CR_df = pd.DataFrame(pd.DataFrame(CR_history).T)\n",
    "\n",
    "            S_CR = np.empty(pop_size)\n",
    "            S_F = np.empty(pop_size)\n",
    "            v[:][:]=population[:][:]\n",
    "            for i in range (0, pop_size):\n",
    "                r[i] = int(random.random()*H)\n",
    "                CR[i] = np.random.normal(CR_history[int(r[i])], 0.1)\n",
    "                if CR[i]>1:\n",
    "                    CR[i] = 1\n",
    "                if CR[i]<0:\n",
    "                    CR[i] = 0\n",
    "\n",
    "                F[i] = F_history[int(r[i])]+np.random.standard_cauchy()*0.1\n",
    "                if F[i]>1:\n",
    "                    F[i] = 1\n",
    "                while( F[i]<0):\n",
    "                    F[i] = F_history[int(r[i])]+np.random.standard_cauchy()*0.1\n",
    "                p[i] = random.random()*(0.2-pmin)+pmin\n",
    "\n",
    "                r1, r2, pbest = generate_indices(pop_size, A, p, i)\n",
    "\n",
    "                j_rand = int(random.random()*N)\n",
    "                for j in range (0,n1):\n",
    "                    if (random.random()<CR[i] or j == j_rand):\n",
    "                        if (r2 < pop_size):\n",
    "                            v[i][j] = population[i][j]+F[i]*(population[pbest][j]-population[i][j])+F[i]*(population[r1][j]-population[r2][j])                       \n",
    "                        if (r2 >= pop_size):\n",
    "                            r2 = r2-pop_size\n",
    "                            v[i][j] = population[i][j]+F[i]*(population[pbest][j]-population[i][j])+F[i]*(population[r1][j]-archive[r2][j])\n",
    "\n",
    "                for j in range (n1,n1 + n2):\n",
    "\n",
    "                    if (random.random()<CR[i] or j == j_rand):\n",
    "                        rnd_bool_var = pop_size+1\n",
    "                        var_list = [i,pbest,r1,r2]\n",
    "                        while (rnd_bool_var >= pop_size):  \n",
    "                            rnd_bool_var = random.choice(var_list)\n",
    "\n",
    "                        v[i][j] = population[rnd_bool_var][j]\n",
    "\n",
    "\n",
    "                if (random.random()<(1.0/(n2))):\n",
    "                    rnd_ind =random.randint(n1, n1 + n2-1) \n",
    "                    if (v[i][rnd_ind] == 0):\n",
    "                        v[i][rnd_ind] =1\n",
    "                    else:\n",
    "                         v[i][rnd_ind] =1\n",
    "\n",
    "                for j in range (0,n1):\n",
    "                    if ( (isNaN(v[i][j]) == 1)):\n",
    "                        if variable_type[j] == 'real':\n",
    "                            v[i][j] = random.uniform(a[j], b[j])\n",
    "                        if variable_type[j] == 'int':\n",
    "                            v[i][j] = random.randint(int(a[j]), int(b[j]))\n",
    "\n",
    "                check_sum_ones = 0\n",
    "                for j in range (n1,n1 + n2):\n",
    "                    if (v[i][j] == 1):\n",
    "                        check_sum_ones = check_sum_ones +1\n",
    "                if (check_sum_ones == 0):\n",
    "                    v[i][random.randint(n1, n1 + n2-1)] = 1\n",
    "                borders (v, population, N, a, b, variable_type)\n",
    "\n",
    "            w = np.array([])\n",
    "            S_CR = np.array([])\n",
    "            S_F = np.array([])\n",
    "            for i in range (0, pop_size):\n",
    "\n",
    "                solution = v[i][:]\n",
    "                x = solution = v[i][:]\n",
    "                fit = fitness_function(data_test_1,data_train_1, data_test_2,data_train_2,data_test_3,data_train_3,data_test_4,data_train_4,x, variable_type ,n1, n2, goal_number_of_features)\n",
    "                tf.keras.backend.clear_session()\n",
    "                fitness_new[i] = fit\n",
    "                FEV = FEV-1\n",
    "                if (fitness_new[i]<fitness[i]):\n",
    "                    S_CR = np.append(S_CR, CR[i])\n",
    "                    S_F = np.append(S_F, F[i])\n",
    "                    w = np.append(w,(fitness[i]-fitness_new[i]))\n",
    "                    if (A<archive_size):\n",
    "                        archive[i] = population[i][:]\n",
    "                        A=A+1\n",
    "                    if (A >= archive_size):\n",
    "                        rnd_index = int(random.random()*archive_size)\n",
    "                        archive[rnd_index] = population[i][:]\n",
    "\n",
    "                    population[i][:] = solution\n",
    "\n",
    "                    fitness[i] =fitness_new[i]\n",
    "\n",
    "                    if (fitness[i]<global_best):\n",
    "                        global_best = fitness[i]\n",
    "                        best_solution = solution.copy()\n",
    "\n",
    "                if (FEV % kratnost == 0):\n",
    "                    tracking_fitness.append(global_best)\n",
    "                    tracking_solution = (best_solution)\n",
    "\n",
    "            total_w = np.sum(w)\n",
    "            w = w/total_w\n",
    "\n",
    "            new_CR = np.sum(w*S_F)\n",
    "            new_F = np.sum(w*S_F*S_F)/np.sum(w*S_F)\n",
    "            if (new_CR >0 and new_F>0):\n",
    "                F_history[k]=new_F\n",
    "                CR_history[k]=new_CR\n",
    "                k=k+1\n",
    "                if (k>H-1):\n",
    "                    k=0\n",
    "\n",
    "        RUNS = RUNS - 1\n",
    "        tracking_fitness = pd.DataFrame(tracking_fitness)\n",
    "\n",
    "        fitness_stat = pd.concat([fitness_stat,tracking_fitness], axis=1)\n",
    "        solution_stat.append(tracking_solution)\n",
    "\n",
    "        best_in_RUN.append(global_best)\n",
    "        best_solution[0] = int(best_solution[0])\n",
    "        best_solution[1] = int(best_solution[1])\n",
    "        best_solution[2] = int(best_solution[2])\n",
    "        best_solution[3] = int(best_solution[3])\n",
    "        df_stats.iloc[RUNS,:len(best_solution)] = best_solution#########################\n",
    "        criberions = calc_criterions(best_solution,n1,n2)\n",
    "\n",
    "        df_stats.iloc[RUNS]['MAE_train'] = criberions[0]\n",
    "        df_stats.iloc[RUNS]['MAE_val'] = criberions[1]\n",
    "        df_stats.iloc[RUNS]['MAE_test'] = criberions[2]\n",
    "\n",
    "        df_stats.iloc[RUNS]['MSE_train'] = criberions[3]\n",
    "        df_stats.iloc[RUNS]['MSE_val'] = criberions[4]\n",
    "        df_stats.iloc[RUNS]['MSE_test'] = criberions[5]\n",
    "\n",
    "        df_stats.iloc[RUNS]['R2_train'] = criberions[6]\n",
    "        df_stats.iloc[RUNS]['R2_val'] = criberions[7]\n",
    "        df_stats.iloc[RUNS]['R2_test'] = criberions[8]\n",
    "\n",
    "        df_stats.iloc[RUNS]['IA_train'] = criberions[9]\n",
    "        df_stats.iloc[RUNS]['IA_val'] = criberions[10]\n",
    "        df_stats.iloc[RUNS]['IA_test'] = criberions[11]\n",
    "\n",
    "    file_name = 'NN_' + str(goal_number_of_features)+'.csv'\n",
    "    df_stats.to_csv('NN_' + str(goal_number_of_features)+'.csv')\n",
    "    fitness_stat.to_csv('NN_fitness' + str(goal_number_of_features)+'.csv')\n",
    "    test = solution_stat.copy()\n",
    "    test.append(best_in_RUN)\n",
    "    test = pd.DataFrame(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
