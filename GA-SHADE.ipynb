{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045aede1-07c0-4431-969f-82a65e69cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "def index_of_agreement (s, o):\n",
    "\n",
    "    s,o = filter_nan(s,o)\n",
    "    ia = 1 -(np.sum((o-s)**2))/(np.sum((np.abs(s-np.mean(o))+np.abs(o-np.mean(o)))**2))\n",
    "    return ia\n",
    "def filter_nan(s,o):\n",
    "    \"\"\"\n",
    "    this functions removed the data  from simulated and observed data\n",
    "    whereever the observed data contains nan\n",
    "    \n",
    "    this is used by all other functions, otherwise they will produce nan as \n",
    "    output\n",
    "    \"\"\"\n",
    "    s = np.array(s.copy())\n",
    "    o = np.array(o.copy())\n",
    "    data = np.array([s.flatten(),o.flatten()])\n",
    "    data = np.transpose(data)\n",
    "    data = data[~np.isnan(data).any(1)]\n",
    "    s = data[:,0]\n",
    "    o = data[:,1]\n",
    "    return s, o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0b4d2-d5c2-47ed-9fa6-a75c2a9bf41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function(data, x, variable_type, n1, n2, goal_number_of_features):\n",
    "    FEATURES = ['Temp','T_lag_1', 'T_lag_2', 'T_lag_3', 'E_lag_1', 'E_lag_2', 'E_lag_3','t_cos','t_sin', 'd_cos', 'd_sin', 'w_cos',  'w_sin', 'm_cos', 'm_sin']\n",
    "    TARGET = ['Power']\n",
    "    params = x.copy()\n",
    "    feature_variables = params[n1:]\n",
    "    new_features = []\n",
    "    number_of_ones = 0\n",
    "    \n",
    "    for i in range(0, len(feature_variables)):\n",
    "        if (feature_variables[i] == 1):\n",
    "            new_features += [FEATURES[i]]\n",
    "            number_of_ones = number_of_ones +1\n",
    "    for i in range(0, n1):\n",
    "        \n",
    "        if (variable_type[i] == 'int'):\n",
    "            params[i] = int(params[i])\n",
    "    model = DecisionTreeRegressor(criterion='squared_error',\n",
    "                                 max_depth = int(params[0]), min_samples_split = int(params[1]),\n",
    "                                 min_samples_leaf = int(params[2]), random_state = 42)\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    mae_scores = [] \n",
    "    X = data[new_features]\n",
    "    y = data['Power']\n",
    "    X_train_global, X_test_global, y_train_global, y_test_global = train_test_split(X, y, test_size=0.3, shuffle = False)\n",
    "\n",
    "    \n",
    "    # Perform time series cross-validation\n",
    "    for train_index, test_index in tscv.split(X_train_global):\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test = X_train_global.iloc[train_index], X_train_global.iloc[test_index]\n",
    "        y_train, y_test = y_train_global.iloc[train_index], y_train_global.iloc[test_index]\n",
    "        # Train the model\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mae_scores.append(mae)\n",
    "    average_mae = np.mean(mae_scores)   \n",
    "    penalty = abs(goal_number_of_features -number_of_ones ) +1\n",
    "\n",
    "    return average_mae*penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fc93a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_criterions (data, params,n1,n2):\n",
    "    \n",
    "    FEATURES = ['Temp','T_lag_1', 'T_lag_2', 'T_lag_3', 'E_lag_1', 'E_lag_2', 'E_lag_3','t_cos','t_sin', 'd_cos', 'd_sin', 'w_cos',  'w_sin', 'm_cos', 'm_sin']\n",
    "    TARGET = ['Power']\n",
    "    feature_variables = params[n1:]\n",
    "    new_features = []\n",
    "    number_of_ones = 0\n",
    "    \n",
    "    for i in range(0, len(feature_variables)):\n",
    "        if (feature_variables[i] == 1):\n",
    "            new_features += [FEATURES[i]]\n",
    "            number_of_ones = number_of_ones +1\n",
    "    for i in range(0, n1):\n",
    "        \n",
    "        if (variable_type[i] == 'int'):\n",
    "            params[i] = int(params[i])\n",
    "    model = DecisionTreeRegressor(criterion='squared_error', \n",
    "                                 max_depth = int(params[0]), min_samples_split = int(params[1]),\n",
    "                                 min_samples_leaf = int(params[2]), random_state = 42)\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    mae_scores_val = []\n",
    "    mse_scores_val = []\n",
    "    ia_scores_val = []\n",
    "    r2_scores_val = []\n",
    "\n",
    "    X = data[new_features]\n",
    "    y = data['Power']\n",
    "    X_train_global, X_test_global, y_train_global, y_test_global = train_test_split(X, y, test_size=0.3, shuffle = False)\n",
    "    # Perform time series cross-validation\n",
    "    for train_index, test_index in tscv.split(X_train_global):\n",
    "\n",
    "        # Split data\n",
    "        X_train, X_test = X_train_global.iloc[train_index], X_train_global.iloc[test_index]\n",
    "        y_train, y_test = y_train_global.iloc[train_index], y_train_global.iloc[test_index]\n",
    "        # Train the model\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = root_mean_squared_error(y_test, y_pred)\n",
    "        ia = index_of_agreement(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        mae_scores_val.append(mae)\n",
    "        mse_scores_val.append(mae)\n",
    "        ia_scores_val.append(ia)\n",
    "        r2_scores_val.append(r2)\n",
    "        \n",
    "    global_val_MAE = np.mean(mae_scores_val)\n",
    "    global_val_MSE = np.mean(mse_scores_val)\n",
    "    global_val_R2 = np.mean(r2_scores_val)\n",
    "    global_val_IA = np.mean(ia_scores_val)\n",
    "    X = data[new_features]\n",
    "    y = data['Power']\n",
    "    \n",
    "    X_train_global, X_test_global, y_train_global, y_test_global = train_test_split(X, y, test_size=0.3, shuffle = False)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_global = scaler.fit_transform(X_train_global)\n",
    "    X_test_global = scaler.transform(X_test_global)\n",
    "        \n",
    "    model.fit(X_train_global, y_train_global)\n",
    "    \n",
    "    y_pred = model.predict(X_train_global)\n",
    "    global_train_MAE = mean_absolute_error(y_train_global, y_pred)\n",
    "    global_train_MSE = root_mean_squared_error(y_train_global, y_pred)\n",
    "    global_train_IA = index_of_agreement(y_train_global, y_pred)\n",
    "    global_train_R2 = r2_score(y_train_global, y_pred)\n",
    "        \n",
    "    y_pred = model.predict(X_test_global)\n",
    "    global_test_MAE = mean_absolute_error(y_test_global, y_pred)\n",
    "    global_test_MSE = root_mean_squared_error(y_test_global, y_pred)\n",
    "    global_test_IA = index_of_agreement(y_test_global, y_pred)\n",
    "    global_test_R2 = r2_score(y_test_global, y_pred)\n",
    "    \n",
    "    return global_train_MAE, global_val_MAE, global_test_MAE,global_train_MSE,global_val_MSE, global_test_MSE, global_train_R2, global_val_R2, global_test_R2, global_train_IA, global_val_IA, global_test_IA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d2bf4-cbda-44d5-b590-c20b69e0166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import cauchy\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def init_population(population, pop_size, N, a, b, variable_type):\n",
    "    for i in range(0, pop_size):\n",
    "        for j in range (0, N):\n",
    "            if (variable_type[j] == 'real'):\n",
    "                population[i][j] = random.random()*(b[j]-a[j])+a[j]\n",
    "            if (variable_type[j] == 'int'):\n",
    "                population[i][j] = int(random.random()*(b[j]-a[j])+a[j])\n",
    "            if (variable_type[j] == 'bool'):\n",
    "                if (random.random()>0.5):\n",
    "                    population[i][j] = 1\n",
    "                else:\n",
    "                    population[i][j] = 0\n",
    "\n",
    "def generate_indices(pop_size, A, p, i):\n",
    "    r1=int(random.random()*pop_size)\n",
    "    r2=int(random.random()*(pop_size+A))\n",
    "    max_best_number = int(p[i]*pop_size)\n",
    "    bests_fitness = np.argsort(fitness)[:max_best_number]\n",
    "    pbest = np.random.choice(bests_fitness)\n",
    "    while (r1 == r2 or i == r1 or i == r2 ):\n",
    "        r1=int(random.random()*pop_size)\n",
    "        r2=int(random.random()*(pop_size+A))\n",
    "\n",
    "    return r1, r2, pbest\n",
    "\n",
    "def borders (v, population, N, a, b, variable_type):\n",
    "    for i in range(0, pop_size):\n",
    "        for j in range (0, N):\n",
    "            if (variable_type[j] == 'real'):\n",
    "                if (v[i][j] > b[j]):#was if\n",
    "                    v[i][j] = (b[j]+population[i][j])/2\n",
    "                if (v[i][j] < a[j]):\n",
    "                    v[i][j] = (a[j]+population[i][j])/2\n",
    "            if (variable_type[j] == 'int'):\n",
    "                if (v[i][j] > b[j]):\n",
    "                    v[i][j] = int((b[j]+population[i][j])/2)\n",
    "                if (v[i][j] < a[j]):\n",
    "                    v[i][j] = int((a[j]+population[i][j])/2)\n",
    "def isNaN(num):\n",
    "    return num != num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2709e77b-dc9c-42a3-9def-e86556652eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = 3\n",
    "n2 = 15\n",
    "N = n1 + n2\n",
    "pop_size = 50\n",
    "\n",
    "for goal_number_of_features in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]:\n",
    "    RUNS = 7\n",
    "    columns = [\"max_depth\", \"min_samples_split\", \"min_samples_leaf\",'Temp','T_lag_1', 'T_lag_2', 'T_lag_3', 'E_lag_1', 'E_lag_2', 'E_lag_3','t_cos','t_sin', 'd_cos', 'd_sin', 'w_cos',  'w_sin', 'm_cos', 'm_sin',\n",
    "            'MAE_train', 'MSE_train', 'IA_train', 'R2_train',\n",
    "            'MAE_val',   'MSE_val',   'IA_val',   'R2_val',\n",
    "            'MAE_test',  'MSE_test',  'IA_test',  'R2_test'\n",
    "              ]\n",
    "    df_stats = pd.DataFrame(columns = columns, index = range(RUNS))\n",
    "    df_fitness = pd.DataFrame(columns = columns, index = range(RUNS))\n",
    "    \n",
    "    variable_type =  ['int','int','int',\n",
    "                      'bool','bool','bool','bool','bool',\n",
    "                      'bool','bool','bool','bool','bool',\n",
    "                      'bool','bool','bool','bool','bool']\n",
    " \n",
    "    a =[2,2,2]\n",
    "    b = [20,20,20]\n",
    "\n",
    "    archive_size = pop_size\n",
    "    H = 10\n",
    "    \n",
    "    best_in_RUN = []\n",
    "    fitness_stat = pd.DataFrame()\n",
    "    solution_stat = []\n",
    "\n",
    "    while (RUNS>0):\n",
    "\n",
    "        global_best = 1e300\n",
    "        population = np.empty((pop_size,N))\n",
    "        v = np.empty((pop_size,N))\n",
    "        archive = np.empty((archive_size,N))\n",
    "        fitness = np.empty(pop_size)\n",
    "        fitness_new = np.empty(pop_size)\n",
    "        F_history = np.empty(H)\n",
    "        CR_history = np.empty(H)\n",
    "        S_CR = []\n",
    "        S_F = []\n",
    "        w = []\n",
    "        r = np.empty(pop_size)\n",
    "        CR = np.empty(pop_size)\n",
    "        F = np.empty(pop_size)\n",
    "        p = np.empty(pop_size)\n",
    "\n",
    "        FEV = 1500\n",
    "        kratnost = FEV/100\n",
    "        tracking_fitness = []\n",
    "        tracking_solution = []\n",
    "        init_population(population, pop_size, N, a, b, variable_type)\n",
    "\n",
    "        for i in range (0, pop_size):\n",
    "\n",
    "            x = population[i][:]\n",
    "            solution = x.copy()\n",
    "\n",
    "            fit = fitness_function(data,solution, variable_type ,n1, n2, goal_number_of_features)\n",
    "            fitness[i] = fit\n",
    "            fitness_new[i] = fitness[i]\n",
    "            FEV =FEV - 1\n",
    "            \n",
    "            if (fitness[i]<global_best):\n",
    "                global_best = fitness[i]\n",
    "                best_solution = solution.copy()\n",
    "\n",
    "            if (FEV % kratnost == 0):\n",
    "                tracking_fitness.append(global_best)\n",
    "                tracking_solution = (best_solution)\n",
    "                    \n",
    "        F_history[:] = 0.5\n",
    "        CR_history[:] = 0.5\n",
    "        A = 0\n",
    "        k=0\n",
    "        pmin = 5.0/pop_size\n",
    "\n",
    "        while (FEV>0):\n",
    "            CR_df = pd.DataFrame(pd.DataFrame(CR_history).T)\n",
    "\n",
    "            S_CR = np.empty(pop_size)\n",
    "            S_F = np.empty(pop_size)\n",
    "            v[:][:]=population[:][:]\n",
    "            for i in range (0, pop_size):\n",
    "                r[i] = int(random.random()*H)\n",
    "                CR[i] = np.random.normal(CR_history[int(r[i])], 0.1)\n",
    "                if CR[i]>1:\n",
    "                    CR[i] = 1\n",
    "                if CR[i]<0:\n",
    "                    CR[i] = 0\n",
    "\n",
    "                F[i] = F_history[int(r[i])]+np.random.standard_cauchy()*0.1\n",
    "                if F[i]>1:\n",
    "                    F[i] = 1\n",
    "                while (F[i] < 0):\n",
    "                    F[i] = F_history[int(r[i])]+np.random.standard_cauchy()*0.1\n",
    "                p[i] = random.random()*(0.2-pmin)+pmin\n",
    "\n",
    "                r1, r2, pbest = generate_indices(pop_size, A, p, i)\n",
    "\n",
    "                j_rand = int(random.random()*N)\n",
    "                for j in range (0,n1):\n",
    "                    if (random.random()<CR[i] or j == j_rand):\n",
    "                        if (r2 < pop_size):\n",
    "                            v[i][j] = population[i][j]+F[i]*(population[pbest][j]-population[i][j])+F[i]*(population[r1][j]-population[r2][j])                       \n",
    "                        if (r2 >= pop_size):\n",
    "                            r2 = r2-pop_size\n",
    "                            v[i][j] = population[i][j]+F[i]*(population[pbest][j]-population[i][j])+F[i]*(population[r1][j]-archive[r2][j])\n",
    "\n",
    "                for j in range (n1,n1 + n2):\n",
    "\n",
    "                    if (random.random()<CR[i] or j == j_rand):\n",
    "                        rnd_bool_var = pop_size+1\n",
    "                        var_list = [i,pbest,r1,r2]\n",
    "                        while (rnd_bool_var >= pop_size):  \n",
    "                            rnd_bool_var = random.choice(var_list)\n",
    "\n",
    "                        v[i][j] = population[rnd_bool_var][j]\n",
    "\n",
    "\n",
    "                if (random.random()<(1.0/(n2))):\n",
    "                    rnd_ind =random.randint(n1, n1 + n2-1) \n",
    "                    if (v[i][rnd_ind] == 0):\n",
    "                        v[i][rnd_ind] =1\n",
    "                    else:\n",
    "                         v[i][rnd_ind] =1\n",
    "\n",
    "                for j in range (0,n1):\n",
    "                    if ( (isNaN(v[i][j]) == 1)):\n",
    "                        if variable_type[j] == 'real':\n",
    "                            v[i][j] = random.uniform(a[j], b[j])\n",
    "                        if variable_type[j] == 'int':\n",
    "                            v[i][j] = random.randint(int(a[j]), int(b[j]))\n",
    "\n",
    "                chech_sum_ones = 0\n",
    "                for j in range (n1,n1 + n2):\n",
    "                    if (v[i][j] == 1):\n",
    "                        chech_sum_ones = chech_sum_ones +1\n",
    "                if (chech_sum_ones == 0):\n",
    "                    v[i][random.randint(n1, n1 + n2-1)] = 1\n",
    "                borders (v, population, N, a, b, variable_type)\n",
    "\n",
    "\n",
    "\n",
    "            w = np.array([])\n",
    "            S_CR = np.array([])\n",
    "            S_F = np.array([])\n",
    "            for i in range (0, pop_size):\n",
    "\n",
    "                solution = v[i][:]\n",
    "                x = solution = v[i][:]\n",
    "                fit = fitness_function(data, x, variable_type ,n1, n2, goal_number_of_features)\n",
    "                fitness_new[i] = fit\n",
    "                FEV = FEV-1\n",
    "                if (fitness_new[i]<fitness[i]):\n",
    "                    S_CR = np.append(S_CR, CR[i])\n",
    "                    S_F = np.append(S_F, F[i])\n",
    "                    w = np.append(w,(fitness[i]-fitness_new[i]))\n",
    "                    if (A<archive_size):\n",
    "                        archive[i] = population[i][:]\n",
    "                        A=A+1\n",
    "                    if (A >= archive_size):\n",
    "                        rnd_index = int(random.random()*archive_size)\n",
    "                        archive[rnd_index] = population[i][:]\n",
    "\n",
    "                    population[i][:] = solution\n",
    "\n",
    "                    fitness[i] =fitness_new[i]\n",
    "\n",
    "                    if (fitness[i]<global_best):\n",
    "                        global_best = fitness[i]\n",
    "                        best_solution = solution.copy()\n",
    "                        \n",
    "                if (FEV % kratnost == 0):\n",
    "                    tracking_fitness.append(global_best)\n",
    "                    tracking_solution = (best_solution)\n",
    "\n",
    "            total_w = np.sum(w)\n",
    "            w = w/total_w\n",
    "\n",
    "            new_CR = np.sum(w*S_F)\n",
    "            new_F = np.sum(w*S_F*S_F)/np.sum(w*S_F)\n",
    "            if (new_CR >0 and new_F>0):\n",
    "                F_history[k]=new_F\n",
    "                CR_history[k]=new_CR\n",
    "                k=k+1\n",
    "                if (k>H-1):\n",
    "                    k=0\n",
    "\n",
    "        RUNS = RUNS - 1\n",
    "        tracking_fitness = pd.DataFrame(tracking_fitness)\n",
    "    \n",
    "        fitness_stat = pd.concat([fitness_stat,tracking_fitness], axis=1)\n",
    "        solution_stat.append(tracking_solution)\n",
    "        \n",
    "        best_in_RUN.append(global_best)\n",
    "        best_solution[0] = int(best_solution[0])\n",
    "        best_solution[1] = int(best_solution[1])\n",
    "        best_solution[2] = int(best_solution[2])\n",
    "        best_solution[3] = int(best_solution[3])\n",
    "        df_stats.iloc[RUNS,:len(best_solution)] = best_solution\n",
    "        criberions = calc_criterions(data,best_solution,n1,n2)\n",
    "        df_stats.iloc[RUNS]['MAE_train'] = criberions[0]\n",
    "        df_stats.iloc[RUNS]['MAE_val'] = criberions[1]\n",
    "        df_stats.iloc[RUNS]['MAE_test'] = criberions[2]\n",
    "        \n",
    "        df_stats.iloc[RUNS]['MSE_train'] = criberions[3]\n",
    "        df_stats.iloc[RUNS]['MSE_val'] = criberions[4]\n",
    "        df_stats.iloc[RUNS]['MSE_test'] = criberions[5]\n",
    "        \n",
    "        df_stats.iloc[RUNS]['R2_train'] = criberions[6]\n",
    "        df_stats.iloc[RUNS]['R2_val'] = criberions[7]\n",
    "        df_stats.iloc[RUNS]['R2_test'] = criberions[8]\n",
    "        \n",
    "        df_stats.iloc[RUNS]['IA_train'] = criberions[9]\n",
    "        df_stats.iloc[RUNS]['IA_val'] = criberions[10]\n",
    "        df_stats.iloc[RUNS]['IA_test'] = criberions[11]\n",
    "    \n",
    "    file_name = 'DT_' + str(goal_number_of_features)+'_.csv'\n",
    "    df_stats.to_csv('DT_' + str(goal_number_of_features)+'_.csv')\n",
    "    fitness_stat.to_csv('DT_fitness' + str(goal_number_of_features)+'_.csv')\n",
    "    test = solution_stat.copy()\n",
    "    test.append(best_in_RUN)\n",
    "    test = pd.DataFrame(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
